{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","execution":{"iopub.execute_input":"2024-11-20T12:54:33.090798Z","iopub.status.busy":"2024-11-20T12:54:33.090335Z","iopub.status.idle":"2024-11-20T12:54:33.325726Z","shell.execute_reply":"2024-11-20T12:54:33.324767Z","shell.execute_reply.started":"2024-11-20T12:54:33.090744Z"},"trusted":true},"outputs":[],"source":["import json \n","with open(\"/kaggle/input/dataset-contractnli/train.json\") as file:\n","    data = json.load(file)\n","\n","with open(\"/kaggle/input/validation-contract/dev.json\") as file:\n","    val_data = json.load(file)\n","\n","with open(\"/kaggle/input/dataset-contractnli/test.json\") as file:\n","    test_data = json.load(file)\n","\n"]},{"cell_type":"code","execution_count":2,"metadata":{"execution":{"iopub.execute_input":"2024-11-20T12:54:33.328028Z","iopub.status.busy":"2024-11-20T12:54:33.327645Z","iopub.status.idle":"2024-11-20T12:54:33.333288Z","shell.execute_reply":"2024-11-20T12:54:33.332312Z","shell.execute_reply.started":"2024-11-20T12:54:33.327988Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["423\n"]}],"source":["# print(data)\n","data[\"documents\"] = data[\"documents\"]\n","print(len(data[\"documents\"]))"]},{"cell_type":"code","execution_count":3,"metadata":{"execution":{"iopub.execute_input":"2024-11-20T12:54:33.334680Z","iopub.status.busy":"2024-11-20T12:54:33.334393Z","iopub.status.idle":"2024-11-20T12:54:36.844632Z","shell.execute_reply":"2024-11-20T12:54:36.843703Z","shell.execute_reply.started":"2024-11-20T12:54:33.334657Z"},"trusted":true},"outputs":[],"source":["import random\n","import torch\n","from torch.utils.data import Dataset\n","\n","class TrainDataset(Dataset):\n","    def __init__(self, document_data, tokenizer, max_length=128):\n","        self.tokenizer = tokenizer\n","        self.max_length = max_length\n","        self.data = self.process_data(document_data)\n","\n","    def process_data(self, document_data):\n","        \"\"\"Process the document data to create labeled pairs of text and hypothesis.\"\"\"\n","        data = []\n","        for document in document_data[\"documents\"]:\n","            # for annotation_set in document[\"annotation_sets\"]:\n","            annotation_set = document[\"annotation_sets\"][0]\n","            annotations = annotation_set[\"annotations\"]\n","            for nda, annotation in annotations.items():\n","                if annotation[\"choice\"] == \"Contradiction\":\n","                    spans_text, random_texts = self.get_spans_text(document, annotation)\n","                    hypothesis = document_data[\"labels\"][nda][\"hypothesis\"].lower()\n","                    \n","                    data.extend([(text ,hypothesis, 1) for text in spans_text])\n","                    data.extend([(text ,hypothesis, 0) for text in random_texts])\n","                    # if annotation[\"choice\"] == \"Contradiction\":\n","                    #     spans_text, random_texts = self.get_spans_text(document, annotation)\n","                    #     hypothesis = document_data[\"labels\"][nda][\"hypothesis\"].lower()\n","                        \n","                    #     data.extend([(text, hypothesis, 0) for text in spans_text])\n","                        # # data.extend([(text, hypothesis, 0) for text in random_texts])\n","        return data\n","\n","    def get_spans_text(self, document, annotation):\n","        \"\"\"Retrieve both labeled and random spans for a given document.\"\"\"\n","        spans_indices = annotation[\"spans\"]\n","        document_spans = document[\"spans\"]\n","        \n","        # Retrieve labeled spans\n","        spans = [document_spans[i] for i in spans_indices]\n","        spans_text = [document[\"text\"][start:end].lower() for start, end in spans]\n","        \n","        # Retrieve random spans, ensuring no overlap with labeled spans\n","        random_indices = random.sample(range(len(document_spans)), 2)\n","        random_indices = [i for i in random_indices if i not in spans_indices]\n","        random_spans = [document_spans[i] for i in random_indices]\n","        random_texts = [document[\"text\"][start:end].lower() for start, end in random_spans]\n","\n","        return spans_text, random_texts\n","\n","    def __len__(self):\n","        return len(self.data)\n","\n","    def __getitem__(self, idx):\n","        text, hypothesis, label = self.data[idx]\n","        encoding = self.encode_example(text, hypothesis)\n","        return {\"input_ids\": encoding[\"input_ids\"].squeeze(), \n","                \"attention_mask\": encoding[\"attention_mask\"].squeeze(), \n","                \"label\": label}\n","\n","    def encode_example(self, text, hypothesis):\n","        \"\"\"Encode a text-hypothesis pair using the tokenizer.\"\"\"\n","        return self.tokenizer(\n","            text, hypothesis, max_length=self.max_length, \n","            padding=\"max_length\", truncation=True, \n","            return_tensors=\"pt\", return_attention_mask=True\n","        )\n","\n","def collate_fn(batch):\n","    \"\"\"Custom collate function to combine batch samples into a batch tensor format.\"\"\"\n","    input_ids = torch.stack([item[\"input_ids\"] for item in batch])\n","    attention_mask = torch.stack([item[\"attention_mask\"] for item in batch])\n","    labels = torch.tensor([item[\"label\"] for item in batch])\n","\n","    return {\n","        \"input_ids\": input_ids,\n","        \"attention_mask\": attention_mask,\n","        \"labels\": labels\n","    }\n"]},{"cell_type":"code","execution_count":4,"metadata":{"execution":{"iopub.execute_input":"2024-11-20T12:54:36.846937Z","iopub.status.busy":"2024-11-20T12:54:36.846598Z","iopub.status.idle":"2024-11-20T13:27:37.067961Z","shell.execute_reply":"2024-11-20T13:27:37.067243Z","shell.execute_reply.started":"2024-11-20T12:54:36.846911Z"},"trusted":true},"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"ff60d8535d3642a4852471fb48417dd9","version_major":2,"version_minor":0},"text/plain":["tokenizer_config.json:   0%|          | 0.00/48.0 [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"9d797adb0d5b49d19b77138ac19391ff","version_major":2,"version_minor":0},"text/plain":["vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"ae9324399cc14b12ba46b927005b34d3","version_major":2,"version_minor":0},"text/plain":["tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"9d4608c5d8a04d3686e66bc060a53b71","version_major":2,"version_minor":0},"text/plain":["config.json:   0%|          | 0.00/570 [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"e6c4d92379c64bc18209483583893755","version_major":2,"version_minor":0},"text/plain":["model.safetensors:   0%|          | 0.00/440M [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","/opt/conda/lib/python3.10/site-packages/transformers/training_args.py:1545: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ðŸ¤— Transformers. Use `eval_strategy` instead\n","  warnings.warn(\n","\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m The `run_name` is currently set to the same value as `TrainingArguments.output_dir`. If this was not intended, please specify a different run name by setting the `TrainingArguments.run_name` parameter.\n","\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend. Please refer to https://wandb.me/wandb-core for more information.\n","\u001b[34m\u001b[1mwandb\u001b[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n","\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n","\u001b[34m\u001b[1mwandb\u001b[0m: Paste an API key from your profile and hit enter, or press ctrl+c to quit:"]},{"name":"stdout","output_type":"stream","text":["  Â·Â·Â·Â·Â·Â·Â·Â·\n"]},{"name":"stderr","output_type":"stream","text":["\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"61ee060fb62d45fb9d60f0945ebca043","version_major":2,"version_minor":0},"text/plain":["VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.011113824444444415, max=1.0â€¦"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Tracking run with wandb version 0.18.3"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Run data is saved locally in <code>/kaggle/working/wandb/run-20241120_131523-gfua9hse</code>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Syncing run <strong><a href='https://wandb.ai/manav_shah/huggingface/runs/gfua9hse' target=\"_blank\">./results</a></strong> to <a href='https://wandb.ai/manav_shah/huggingface' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View project at <a href='https://wandb.ai/manav_shah/huggingface' target=\"_blank\">https://wandb.ai/manav_shah/huggingface</a>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View run at <a href='https://wandb.ai/manav_shah/huggingface/runs/gfua9hse' target=\"_blank\">https://wandb.ai/manav_shah/huggingface/runs/gfua9hse</a>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["\n","    <div>\n","      \n","      <progress value='404' max='404' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [404/404 12:07, Epoch 4/4]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Epoch</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>1</td>\n","      <td>0.427000</td>\n","      <td>0.441098</td>\n","    </tr>\n","    <tr>\n","      <td>2</td>\n","      <td>0.308500</td>\n","      <td>0.382412</td>\n","    </tr>\n","    <tr>\n","      <td>3</td>\n","      <td>0.249200</td>\n","      <td>0.367412</td>\n","    </tr>\n","    <tr>\n","      <td>4</td>\n","      <td>0.240500</td>\n","      <td>0.361799</td>\n","    </tr>\n","  </tbody>\n","</table><p>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":["TrainOutput(global_step=404, training_loss=0.32676095095011265, metrics={'train_runtime': 1959.4157, 'train_samples_per_second': 6.565, 'train_steps_per_second': 0.206, 'total_flos': 3384660616151040.0, 'train_loss': 0.32676095095011265, 'epoch': 4.0})"]},"execution_count":4,"metadata":{},"output_type":"execute_result"}],"source":["import torch\n","from transformers import Trainer, TrainingArguments, EarlyStoppingCallback\n","from transformers import BertTokenizer, BertForSequenceClassification\n","from torch.utils.data import DataLoader\n","from transformers import DataCollatorWithPadding\n","\n","# from transformers import AutoModelForSeq2SeqLM, AutoTokenizer\n","# model = AutoModelForSeq2SeqLM.from_pretrained(\"google/flan-t5-small\")\n","# tokenizer = AutoTokenizer.from_pretrained(\"google/flan-t5-small\")\n","\n","# Set device\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","\n","# Initialize tokenizer and model with dropout rate set in the configuration\n","tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n","model = BertForSequenceClassification.from_pretrained('bert-base-uncased', num_labels=2).to(device)\n","\n","# Create training and validation datasets\n","train_dataset = TrainDataset(data, tokenizer, max_length=512)\n","val_dataset = TrainDataset(val_data, tokenizer, max_length=512)\n","data_collator = DataCollatorWithPadding(tokenizer=tokenizer)\n","\n","# Define training arguments with regularization adjustments\n","training_args = TrainingArguments(\n","    output_dir='./results',\n","    evaluation_strategy=\"epoch\",           # evaluate at the end of each epoch\n","    learning_rate=1e-5,                    # use a lower learning rate\n","    per_device_train_batch_size=32,\n","    per_device_eval_batch_size=32,\n","    num_train_epochs=4,\n","    weight_decay=0.01,                     # apply weight decay\n","    logging_dir='./logs',\n","    logging_steps=10,\n","    save_strategy=\"epoch\",\n","    load_best_model_at_end=True,           # load the best model based on validation loss\n",")\n","\n","# Add early stopping to the Trainer to stop if no improvement is seen\n","early_stopping = EarlyStoppingCallback(early_stopping_patience=2)\n","\n","# Initialize the Trainer\n","trainer = Trainer(\n","    model=model,\n","    args=training_args,\n","    train_dataset=train_dataset,\n","    eval_dataset=val_dataset,\n","    data_collator=data_collator,\n","    callbacks=[early_stopping]            \n",")\n","\n","# Train the model\n","trainer.train()\n"]},{"cell_type":"code","execution_count":5,"metadata":{"execution":{"iopub.execute_input":"2024-11-20T13:27:37.069479Z","iopub.status.busy":"2024-11-20T13:27:37.069095Z","iopub.status.idle":"2024-11-20T13:27:59.966087Z","shell.execute_reply":"2024-11-20T13:27:59.965286Z","shell.execute_reply.started":"2024-11-20T13:27:37.069441Z"},"trusted":true},"outputs":[{"data":{"text/html":["<a href='out.zip' target='_blank'>out.zip</a><br>"],"text/plain":["/kaggle/working/out.zip"]},"metadata":{},"output_type":"display_data"}],"source":["import os\n","import subprocess\n","from IPython.display import FileLink, display\n","torch.save(model.state_dict(), 'model_entailment.pth')\n","\n","def download_file(path, download_file_name):\n","    os.chdir('/kaggle/working/')\n","    zip_name = f\"/kaggle/working/{download_file_name}.zip\"\n","    command = f\"zip {zip_name} {path} -r\"\n","    result = subprocess.run(command, shell=True, capture_output=True, text=True)\n","    if result.returncode != 0:\n","        print(\"Unable to run zip command!\")\n","        print(result.stderr)\n","        return\n","    display(FileLink(f'{download_file_name}.zip'))\n","\n","download_file('model_entailment.pth', 'out')"]},{"cell_type":"code","execution_count":6,"metadata":{"execution":{"iopub.execute_input":"2024-11-20T13:27:59.967442Z","iopub.status.busy":"2024-11-20T13:27:59.967152Z","iopub.status.idle":"2024-11-20T13:27:59.971709Z","shell.execute_reply":"2024-11-20T13:27:59.970825Z","shell.execute_reply.started":"2024-11-20T13:27:59.967388Z"},"trusted":true},"outputs":[],"source":["# from transformers import AutoTokenizer\n","# import torch\n","# # Path to the saved model file in the working directory\n","# model_path = '/kaggle/working/find_tuned_bert_on_contradiction/model.safetensors'  # Replace with the actual filename\n","\n","# # Load the model\n","# model = torch.load(model_path)\n"]},{"cell_type":"code","execution_count":7,"metadata":{"execution":{"iopub.execute_input":"2024-11-20T13:27:59.972851Z","iopub.status.busy":"2024-11-20T13:27:59.972635Z","iopub.status.idle":"2024-11-20T13:28:14.432135Z","shell.execute_reply":"2024-11-20T13:28:14.431263Z","shell.execute_reply.started":"2024-11-20T13:27:59.972829Z"},"trusted":true},"outputs":[{"data":{"text/html":[],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"}],"source":["import torch\n","from sklearn.metrics import average_precision_score\n","from transformers import Trainer\n","import numpy as np\n","\n","test_dataset = TrainDataset(test_data, tokenizer, max_length=512)\n","test_results = trainer.predict(test_dataset)\n","\n","# Retrieve the predicted probabilities (logits) and true labels\n","pred_logits = test_results.predictions\n","true_labels = test_results.label_ids\n","\n","\n","# Sigmoid to get probabilities since we have a binary classification for each span\n","pred_probs = torch.sigmoid(torch.tensor(pred_logits)).numpy()\n","\n"]},{"cell_type":"code","execution_count":8,"metadata":{"execution":{"iopub.execute_input":"2024-11-20T13:28:14.433537Z","iopub.status.busy":"2024-11-20T13:28:14.433243Z","iopub.status.idle":"2024-11-20T13:28:14.452209Z","shell.execute_reply":"2024-11-20T13:28:14.451531Z","shell.execute_reply.started":"2024-11-20T13:28:14.433510Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["(852,) (852, 2)\n","(842,)\n","0.9018567639257294\n"]}],"source":["import sklearn\n","from sklearn import metrics\n","\n","def precision_at_recall(y_true, y_prob, recall: float):\n","    assert 0. <= recall <= 1.0\n","    if len(y_true) == 0 or np.sum(y_true) == 0:\n","        return np.nan\n","    threshs = np.sort(np.unique(y_prob))[::-1]\n","    print(threshs.shape)\n","    # (len(np.unique(y_prob)), len(y_prob)) where first axis show prediction at different thresh\n","    y_preds = y_prob[None, :] >= threshs[:, None]\n","    recalls = np.logical_and(y_true[None, :], y_preds).sum(axis=1) / np.sum(y_true)\n","    assert np.all(recalls == np.sort(recalls))\n","\n","    thresh = threshs[np.where(recalls >= recall)[0][0]]\n","    y_pred = y_prob >= thresh\n","    return sklearn.metrics.precision_score(y_true, y_pred, zero_division=0.)\n","\n","print(true_labels.shape, pred_probs.shape)\n","print(precision_at_recall(true_labels,pred_probs[:,1],0.8))"]},{"cell_type":"code","execution_count":9,"metadata":{"execution":{"iopub.execute_input":"2024-11-20T13:28:14.453551Z","iopub.status.busy":"2024-11-20T13:28:14.453235Z","iopub.status.idle":"2024-11-20T13:28:14.460436Z","shell.execute_reply":"2024-11-20T13:28:14.459461Z","shell.execute_reply.started":"2024-11-20T13:28:14.453525Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["0.8708920187793427\n"]}],"source":["\n","\n","print(sklearn.metrics.accuracy_score(true_labels, np.argmax(pred_probs,axis=1)))"]},{"cell_type":"code","execution_count":10,"metadata":{"execution":{"iopub.execute_input":"2024-11-20T13:28:14.464312Z","iopub.status.busy":"2024-11-20T13:28:14.464058Z","iopub.status.idle":"2024-11-20T13:28:14.477228Z","shell.execute_reply":"2024-11-20T13:28:14.476393Z","shell.execute_reply.started":"2024-11-20T13:28:14.464289Z"},"trusted":true},"outputs":[],"source":["\n","import random\n","import torch\n","from torch.utils.data import Dataset\n","\n","class TestDataset(Dataset):\n","    def __init__(self, document_data, tokenizer, max_length=128):\n","        self.tokenizer = tokenizer\n","        self.max_length = max_length\n","        self.data = self.process_data(document_data)\n","\n","    def process_data(self, document_data):\n","        \"\"\"Process the document data to create labeled pairs of text and hypothesis.\"\"\"\n","        data = []\n","        for document in document_data[\"documents\"]:\n","            for annotation_set in document[\"annotation_sets\"]:\n","                annotations = annotation_set[\"annotations\"]\n","                for nda, annotation in annotations.items():\n","                    if annotation[\"choice\"] == \"Contradiction\":\n","                        spans_text, random_texts = self.get_spans_text(document, annotation)\n","                        hypothesis = document_data[\"labels\"][nda][\"hypothesis\"].lower()\n","                        \n","                        data.extend([(text, hypothesis, 1) for text in spans_text])\n","                        data.extend([(text, hypothesis, 0) for text in random_texts])\n","                   \n","        return data\n","\n","    def get_spans_text(self, document, annotation):\n","        \"\"\"Retrieve both labeled and random spans for a given document.\"\"\"\n","        spans_indices = annotation[\"spans\"]\n","        document_spans = document[\"spans\"]\n","        \n","        # Retrieve labeled spans\n","        spans = [document_spans[i] for i in spans_indices]\n","        spans_text = [document[\"text\"][start:end].lower() for start, end in spans]\n","        \n","        # Retrieve random spans, ensuring no overlap with labeled spans\n","        random_indices = random.sample(range(len(document_spans)), 2)\n","        random_indices = [i for i in random_indices if i not in spans_indices]\n","        random_spans = [document_spans[i] for i in random_indices]\n","        random_texts = [document[\"text\"][start:end].lower() for start, end in random_spans]\n","\n","        return spans_text, random_texts\n","\n","    def __len__(self):\n","        return len(self.data)\n","\n","    def __getitem__(self, idx):\n","        text, hypothesis, label = self.data[idx]\n","        encoding = self.encode_example(text, hypothesis)\n","        return {\"input_ids\": encoding[\"input_ids\"].squeeze(), \n","                \"attention_mask\": encoding[\"attention_mask\"].squeeze(), \n","                \"label\": label}\n","\n","    def encode_example(self, text, hypothesis):\n","        \"\"\"Encode a text-hypothesis pair using the tokenizer.\"\"\"\n","        return self.tokenizer(\n","            text, hypothesis, max_length=self.max_length, \n","            padding=\"max_length\", truncation=True, \n","            return_tensors=\"pt\", return_attention_mask=True\n","        )\n","\n","def collate_fn(batch):\n","    \"\"\"Custom collate function to combine batch samples into a batch tensor format.\"\"\"\n","    input_ids = torch.stack([item[\"input_ids\"] for item in batch])\n","    attention_mask = torch.stack([item[\"attention_mask\"] for item in batch])\n","    labels = torch.tensor([item[\"label\"] for item in batch])\n","\n","    return {\n","        \"input_ids\": input_ids,\n","        \"attention_mask\": attention_mask,\n","        \"labels\": labels\n","    }\n","\n","\n"]},{"cell_type":"markdown","metadata":{},"source":["## Evaluation for Testing Dataset "]},{"cell_type":"code","execution_count":11,"metadata":{"execution":{"iopub.execute_input":"2024-11-20T13:28:14.479108Z","iopub.status.busy":"2024-11-20T13:28:14.478493Z","iopub.status.idle":"2024-11-20T13:28:14.490958Z","shell.execute_reply":"2024-11-20T13:28:14.490041Z","shell.execute_reply.started":"2024-11-20T13:28:14.479081Z"},"trusted":true},"outputs":[],"source":["import torch\n","import torch.nn.functional as F\n","\n","def predict_best_span(model, tokenizer, document, hypothesis, max_length=512, device=\"cuda\"):\n","    \"\"\"\n","    Predict the best evidence span for a given document and hypothesis.\n","    \n","    Args:\n","        model: The trained model (e.g., BERT or similar).\n","        tokenizer: The tokenizer for the model.\n","        document: The document containing spans.\n","        hypothesis: The hypothesis string.\n","        max_length: Maximum token length for inputs.\n","        device: Device to run the model on (\"cuda\" or \"cpu\").\n","    \n","    Returns:\n","        best_span: The span with the highest probability as evidence.\n","        best_prob: The probability of the best span.\n","    \"\"\"\n","    model.eval()\n","    spans = document[\"spans\"]  # List of spans (start, end) in the document\n","    text = document[\"text\"]    # Full document text\n","    span_probs = []\n","\n","    with torch.no_grad():\n","        for span in spans:\n","            start, end = span\n","            span_text = text[start:end].lower()\n","\n","            # Encode the span and hypothesis\n","            inputs = tokenizer(\n","                span_text,\n","                hypothesis,\n","                max_length=max_length,\n","                padding=\"max_length\",\n","                truncation=True,\n","                return_tensors=\"pt\"\n","            ).to(device)\n","\n","            # Predict probabilities\n","            outputs = model(**inputs)\n","            logits = outputs.logits  # Shape: [batch_size, num_labels]\n","            probs = F.softmax(logits, dim=-1)  # Convert logits to probabilities\n","            entailment_prob = probs[0][1].item()  # Probability of \"Entailment\" class\n","            span_probs.append(entailment_prob)\n","\n","    # Select the span with the highest probability\n","    best_idx = torch.argmax(torch.tensor(span_probs)).item()\n","    best_span = spans[best_idx]\n","    best_prob = span_probs[best_idx]\n","\n","    return best_span, best_prob\n"]},{"cell_type":"code","execution_count":12,"metadata":{"execution":{"iopub.execute_input":"2024-11-20T13:28:14.492270Z","iopub.status.busy":"2024-11-20T13:28:14.491966Z","iopub.status.idle":"2024-11-20T13:28:14.547634Z","shell.execute_reply":"2024-11-20T13:28:14.546797Z","shell.execute_reply.started":"2024-11-20T13:28:14.492246Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Best Span: (5, 6)\n","Probability of Best Span: 0.11060833185911179\n"]}],"source":["# Example inputs\n","document = {\n","    \"text\": \"This is a sample contract document text.\",\n","    \"spans\": [(0, 4), (5, 6)]  # Example spans\n","}\n","hypothesis = \"This contract is valid.\"\n","\n","# Predict the best span for the hypothesis\n","best_span, best_prob = predict_best_span(model, tokenizer, document, hypothesis)\n","\n","print(\"Best Span:\", best_span)\n","print(\"Probability of Best Span:\", best_prob)\n"]},{"cell_type":"code","execution_count":2,"metadata":{"execution":{"iopub.execute_input":"2024-11-20T13:28:14.549509Z","iopub.status.busy":"2024-11-20T13:28:14.549145Z","iopub.status.idle":"2024-11-20T13:34:01.280612Z","shell.execute_reply":"2024-11-20T13:34:01.279584Z","shell.execute_reply.started":"2024-11-20T13:28:14.549472Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Mean Average Precision (mAP): 0.52398\n","Precision at Recall 80% (P@R80): 0.45712\n"]}],"source":["import torch\n","import torch.nn.functional as F\n","from sklearn.metrics import average_precision_score\n","\n","def calculate_map_p_at_r80(model, tokenizer, document_data, max_length=512, device=\"cuda\"):\n","    \"\"\"\n","    Calculate mAP and P@R80 for the test dataset.\n","    \n","    Args:\n","        model: Trained model for span predictions.\n","        tokenizer: Tokenizer for the model.\n","        document_data: Dataset containing documents, hypotheses, and ground truth spans.\n","        max_length: Max length for tokenization.\n","        device: Device for computation (\"cuda\" or \"cpu\").\n","    \n","    Returns:\n","        mAP: Mean Average Precision score.\n","        p_at_r80: Precision at Recall 80%.\n","    \"\"\"\n","    model.eval()\n","    all_ap_scores = []\n","    precision_at_r80 = []\n","\n","    with torch.no_grad():\n","        it=0\n","        for document in document_data[\"documents\"]:\n","            print(it)\n","            it+=1\n","            annotation_set = document[\"annotation_sets\"][0]\n","            annotations = annotation_set[\"annotations\"]\n","            all_spans = document[\"spans\"]\n","            text = document[\"text\"]\n","            \n","            for nda, annotation in annotations.items():\n","                if annotation[\"choice\"] == \"Contradiction\":\n","                    hypothesis = document_data[\"labels\"][nda][\"hypothesis\"].lower()\n","                    true_spans = annotation[\"spans\"]  # Ground truth span indices\n","\n","                    # Predict probabilities for all spans\n","                    span_probs = []\n","                    for span in all_spans:\n","                        start, end = span\n","                        span_text = text[start:end].lower()\n","                        inputs = tokenizer(\n","                            span_text,\n","                            hypothesis,\n","                            max_length=max_length,\n","                            padding=\"max_length\",\n","                            truncation=True,\n","                            return_tensors=\"pt\"\n","                        ).to(device)\n","                        outputs = model(**inputs)\n","                        logits = outputs.logits\n","                        probs = F.softmax(logits, dim=-1)\n","                        entailment_prob = probs[0][1].item()  # Probability of \"Entailment\" class\n","                        span_probs.append(entailment_prob)\n","\n","                    # Calculate Average Precision (AP) for this document-hypothesis pair\n","                    true_labels = [1 if i in true_spans else 0 for i in range(len(all_spans))]\n","                    ap_score = average_precision_score(true_labels, span_probs)\n","                    # print(true_labels, span_probs )\n","                    all_ap_scores.append(ap_score)\n","\n","                    # Sort spans by probabilities\n","                    sorted_indices = sorted(range(len(span_probs)), key=lambda i: span_probs[i], reverse=True)\n","                    sorted_true_labels = [true_labels[i] for i in sorted_indices]\n","\n","                    # Calculate Precision at Recall 80% (P@R80)\n","                    cumulative_true_positives = 0\n","                    recall_threshold = 0.8 * sum(true_labels)\n","                    for i, label in enumerate(sorted_true_labels):\n","                        cumulative_true_positives += label\n","                        if cumulative_true_positives >= recall_threshold:\n","                            precision = cumulative_true_positives / (i + 1)\n","                            precision_at_r80.append(precision)\n","                            break\n","\n","    # Calculate final mAP and P@R80\n","    mAP = sum(all_ap_scores) / len(all_ap_scores) if all_ap_scores else 0\n","    p_at_r80 = sum(precision_at_r80) / len(precision_at_r80) if precision_at_r80 else 0\n","\n","    return mAP, p_at_r80\n","\n","# Example Usage\n","mAP, p_at_r80 = calculate_map_p_at_r80(model, tokenizer, test_data, max_length=512, device=\"cuda\")\n","print(f\"Mean Average Precision (mAP): {mAP}\")\n","print(f\"Precision at Recall 80% (P@R80): {p_at_r80}\")\n"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":[]}],"metadata":{"kaggle":{"accelerator":"gpu","dataSources":[{"datasetId":2567801,"sourceId":4365768,"sourceType":"datasetVersion"},{"datasetId":5830640,"sourceId":9566627,"sourceType":"datasetVersion"},{"datasetId":6044228,"sourceId":9850442,"sourceType":"datasetVersion"},{"datasetId":6044401,"sourceId":9850683,"sourceType":"datasetVersion"}],"dockerImageVersionId":30787,"isGpuEnabled":true,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.10"}},"nbformat":4,"nbformat_minor":4}
